{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive RAG Agent with Langgraph\n",
    " - Follows ideas from 3 papers:\n",
    "\n",
    "    1. Adaptive RAG - Route questions to different retrieval approaches.\n",
    "    2. Corrective RAG - Fallback to web search if docs are not relevant to query.\n",
    "    3. Self Correction in RAG - Fix answers w/ hallucinations or don't address question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ollama pull llama3.2:3b-instruct-fp16\n",
    "# pip install langchain-nomic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports \n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_nomic.embeddings import NomicEmbeddings\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "# schemas are all base interfaces of langchain\n",
    "from langchain.schema import Document\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph import END\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal, List, Annotated, TypedDict\n",
    "import operator\n",
    "import json\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../secrets/local.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schemas\n",
    "class Grader(BaseModel):\n",
    "    binary_score: Literal['yes', 'no'] = Field(description=\"The final grade / score assigned.\")\n",
    "\n",
    "class ReasoningGrader(BaseModel):\n",
    "    binary_score: Literal['yes', 'no'] = Field(description=\"The final grade / score assigned.\")\n",
    "    explanation: str = Field(description=\"The step by step explanation of the final binary score.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LLM  \n",
    "local_llm = \"llama3.2:3b-instruct-fp16\"\n",
    "llm = ChatOllama(name=\"llama\", model=local_llm, request_timeout=120.0)\n",
    "llm_json_mode = ChatOllama(name=\"llama\", model=local_llm, request_timeout=120.0, json_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm not sure I understand what you're asking. Could you please provide more context or clarify your question? I'll do my best to help.\", additional_kwargs={}, response_metadata={'model': 'llama3.2:3b-instruct-fp16', 'created_at': '2024-11-11T11:52:49.884110491Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 449733628, 'load_duration': 8787279, 'prompt_eval_count': 25, 'prompt_eval_duration': 23484000, 'eval_count': 31, 'eval_duration': 375595000}, id='run-a7d51a7a-a048-44a6-97bb-73654ca3e2f9-0', usage_metadata={'input_tokens': 25, 'output_tokens': 31, 'total_tokens': 56})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "urls = [\n",
    "    \"https://www.promptingguide.ai/introduction/tips/\",\n",
    "    \"https://www.promptingguide.ai/techniques/cot/\",\n",
    "    \"https://www.promptingguide.ai/techniques/meta-prompting/\",\n",
    "    \"https://www.promptingguide.ai/techniques/prompt_chaining/\",\n",
    "    \"https://agentprotocol.ai/protocol/\",\n",
    "    \"https://agentprotocol.ai/\",\n",
    "]\n",
    "\n",
    "\n",
    "# Load the documents\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000, chunk_overlap=200\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(documents=docs_list)\n",
    "\n",
    "# Add vectorDB\n",
    "vector_store = FAISS.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=NomicEmbeddings(model=\"nomic-embed-text-v1.5\", inference_mode=\"local\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create retriever\n",
    "rag_retriever = vector_store.as_retriever(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Web search tool\n",
    "web_search_tool = TavilySearchResults(k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasource': 'vectorstore'} {'datasource': 'websearch'}\n"
     ]
    }
   ],
   "source": [
    "### Router\n",
    "\n",
    "# Prompt\n",
    "router_instructions =\\\n",
    "    \"You are an expert at routing user questions to either a vectorstore or web search. \"\\\n",
    "    \"The vectorstore contains documents related to prompt engineering & agent protocol. \"\\\n",
    "    \"Use the vectorstore for questions related to those topics. For all else, especially for current events, use websearch. \"\\\n",
    "    \"Return JSON with single key, datasource, that is `websearch` or `vectorstore` depending on question.\"\n",
    "\n",
    "# test router\n",
    "test_vectorstore = llm_json_mode.invoke(\n",
    "    [SystemMessage(content=router_instructions)]\n",
    "    + [HumanMessage(content=\"What are the types of prompting?\")]\n",
    ")\n",
    "\n",
    "\n",
    "test_websearch = llm_json_mode.invoke(\n",
    "    [SystemMessage(content=router_instructions)]\n",
    "    + [HumanMessage(content=\"How is the stock market doing ?\")]\n",
    ")\n",
    "\n",
    "print(json.loads(test_vectorstore.content), json.loads(test_websearch.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Document grader\n",
    "\n",
    "# instructions\n",
    "doc_grader_instructions = \"\"\"\n",
    "    You are a grader assessing the relevance of a retrieved document to user question.\n",
    "    If document contains keyword(s) or semantic information relevant to a given question, grade it as relevant.\n",
    "\"\"\"\n",
    "\n",
    "# Grader prompt\n",
    "doc_grader_prompt = \"\"\"\n",
    "    Here is the retrieved document:\n",
    "\n",
    "    {document}\n",
    "\n",
    "    Here is the user question:\n",
    "\n",
    "    {question}.\n",
    "    Carefully and objectively assess whether the document contains at least some amount of relevant information about the asked question.\n",
    "    Return JSON with a single key, binary_score, that is 'yes' or 'no' score.\"\"\"\n",
    "\n",
    "# Test\n",
    "question = \"What is Agent protocol\"\n",
    "docs =  rag_retriever.invoke(question)\n",
    "doc_txt = docs[1].page_content\n",
    "doc_grader_prompt_formatted = doc_grader_prompt.format(\n",
    "    document=doc_txt, question=question\n",
    ")\n",
    "result = llm_json_mode.with_structured_output(Grader).invoke(\n",
    "    [SystemMessage(content=doc_grader_instructions)]\n",
    "    + [HumanMessage(content=doc_grader_prompt_formatted)]\n",
    ")\n",
    "# json.loads(result.content.strip('```'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Agent Protocol is a process used in Zero-Shot-CoT (ZSCoT) that involves two stages: question clustering and demonstration sampling. In Stage 1, questions are clustered into a few groups based on their characteristics such as length and number of steps in the rationale. This is done to select representative questions from each cluster for further generation of reasoning chains using simple heuristics.\n"
     ]
    }
   ],
   "source": [
    "### Generate\n",
    "\n",
    "# Prompt\n",
    "rag_prompt = \"\"\"\n",
    "    You are an assistant for question-answering tasks.\n",
    "\n",
    "    Here is the context to use to answer the question.\n",
    "\n",
    "    {context}\n",
    "\n",
    "    Think carefully about the above context.\n",
    "\n",
    "    Now, review the user question.\n",
    "\n",
    "    {question}\n",
    "\n",
    "    Provide an answer to this question using only the above context.\n",
    "\n",
    "    Use three sentences at maximum to keep the answer concise.\n",
    "\n",
    "    Answer:\"\"\"\n",
    "\n",
    "# post processing\n",
    "def format_docs(docs):\n",
    "    return '\\n\\n'.join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Test\n",
    "docs = rag_retriever.invoke(question)\n",
    "docs_txt = format_docs(docs)\n",
    "rag_prompt_formatted = rag_prompt.format(context=docs_txt, question=question)\n",
    "\n",
    "generation = llm.invoke([SystemMessage(content=rag_prompt)] + [HumanMessage(content=rag_prompt_formatted)])\n",
    "print(generation.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Protocol is a process described in Zhang et al. (2022) that involves two stages: question clustering and demonstration sampling. In Stage 1, questions are partitioned into clusters based on certain criteria such as question length or number of steps in rationale. Stage 2 involves selecting representative questions from each cluster and generating their reasoning chains using Zero-Shot-CoT with simple heuristics.\n"
     ]
    }
   ],
   "source": [
    "### Generate\n",
    "\n",
    "# Prompt\n",
    "rag_prompt = \"\"\"\n",
    "    You are an assistant for question-answering tasks.\n",
    "\n",
    "    Here is the context to use to answer the question.\n",
    "\n",
    "    {context}\n",
    "\n",
    "    Think carefully about the above context.\n",
    "\n",
    "    Now, review the user question.\n",
    "\n",
    "    {question}\n",
    "\n",
    "    Provide an answer to this question using only the above context.\n",
    "\n",
    "    Use three sentences at maximum to keep the answer concise.\n",
    "\n",
    "    Answer:\"\"\"\n",
    "\n",
    "# post processing\n",
    "def format_docs(docs):\n",
    "    return '\\n\\n'.join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Test\n",
    "docs = rag_retriever.invoke(question)\n",
    "docs_txt = format_docs(docs)\n",
    "rag_prompt_formatted = rag_prompt.format(context=docs_txt, question=question)\n",
    "\n",
    "generation = llm.invoke([SystemMessage(content=rag_prompt)] + [HumanMessage(content=rag_prompt_formatted)])\n",
    "print(generation.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Protocol is a process that involves two stages: \n",
      "\n",
      "1. Question clustering: partitioning questions into clusters, and \n",
      "2. Demonstration sampling: selecting representative questions from each cluster and generating their reasoning chains using Zero-Shot-CoT with simple heuristics such as length of questions and number of steps in rationale.\n",
      "\n",
      "This protocol aims to encourage the model to use simple and accurate demonstrations, ultimately improving the quality of generated responses.\n"
     ]
    }
   ],
   "source": [
    "### Generate\n",
    "\n",
    "# Prompt\n",
    "rag_prompt = \"\"\"\n",
    "    You are an assistant for question-answering tasks.\n",
    "\n",
    "    Here is the context to use to answer the question.\n",
    "\n",
    "    {context}\n",
    "\n",
    "    Think carefully about the above context.\n",
    "\n",
    "    Now, review the user question.\n",
    "\n",
    "    {question}\n",
    "\n",
    "    Provide an answer to this question using only the above context.\n",
    "\n",
    "    Use three sentences at maximum to keep the answer concise.\n",
    "\n",
    "    Answer:\"\"\"\n",
    "\n",
    "# post processing\n",
    "def format_docs(docs):\n",
    "    return '\\n\\n'.join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Test\n",
    "docs = rag_retriever.invoke(question)\n",
    "docs_txt = format_docs(docs)\n",
    "rag_prompt_formatted = rag_prompt.format(context=docs_txt, question=question)\n",
    "\n",
    "generation = llm.invoke([SystemMessage(content=rag_prompt)] + [HumanMessage(content=rag_prompt_formatted)])\n",
    "print(generation.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hallucination Grader\n",
    "\n",
    "# Hallucination Grader instructions\n",
    "hallucination_instructions = \"\"\"\n",
    "    You are a teacher grading a college test.\n",
    "    You will be given FACTS and a STUDENT_ANSWER.\n",
    "    Here is the criteria for grading:\n",
    "\n",
    "    (1) Ensure the STUDENT_ANSWER is grounded in the FACTS.\n",
    "    (2) Ensure the STUDENT_ANSWER does not contain **hallucinated** information outside of the FACTS.\n",
    "\n",
    "    Score: \n",
    "    A score of yes means that the student's answers meets all the above criteria. This is the highest(best) score.\n",
    "    A score of no means that the student's answer does not meet all the criteria. This is the lowest possible score.\n",
    "\n",
    "    Explain your reasoning in step-by-step fashion to ensure your reasoning and conclusion are correct.\"\"\"\n",
    "\n",
    "# Prompt\n",
    "hallucination_grader_prompt = \"\"\"\n",
    "    FACTS: \\n\\n {facts} \\n\\n STUDENT_ANSWER: \\n\\n {generation}.\n",
    "    Return JSON with two keys, binary_score, 'yes' or 'no' to indicate whether the STUDENT_ANSWER is grounded in facts. And a key explanation, that contains an explanation of the score.\"\"\"\n",
    "\n",
    "# Test using documents and generation from above.\n",
    "hallucination_grader_prompt_formatted = hallucination_grader_prompt.format(facts=docs_txt, generation=generation)\n",
    "\n",
    "result = llm_json_mode.with_structured_output(ReasoningGrader).invoke(\n",
    "    [SystemMessage(content=hallucination_instructions)] + [HumanMessage(content=hallucination_grader_prompt_formatted)]\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReasoningGrader(binary_score='yes', explanation='The student answer accurately describes the Agent protocol as a two-stage process: question clustering and demonstration sampling. The explanation provided by the model describes how this protocol aims to encourage models to use simple and accurate demonstrations, ultimately improving response quality.')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Answer Grader\n",
    "\n",
    "# answer grader instructions\n",
    "answer_grader_instructions = \"\"\"You are a teacher grading a test.\n",
    "    You will be given a QUESTION and a STUDENT_ANSWER.\n",
    "    Here is the criteria to follow:\n",
    "\n",
    "    (1) The STUDENT_ANSWER helps to answer the QUESTION accurately.\n",
    "\n",
    "    Score:\n",
    "    A score of 'yes' means  that the student's answer meets all of the criteria. This is the highest (best) score.\n",
    "    The student can receive a score of yes if the answer  contains extra information that is not explicitly asked for in the question.\n",
    "\n",
    "    A score of 'no' means  that the student's answer does not meet all of the criteria. This is the lowest possible score.\n",
    "\n",
    "    Explain in a step by step fashion to ensure your reasoning and conclusion are correct.\n",
    "    Avoid simply answering the correct answer right away.\"\"\"\n",
    "\n",
    "# Grader prompt\n",
    "answer_grader_prompt = \"\"\"QUESTION:\n",
    "\n",
    "{question}\n",
    "\n",
    "STUDENT_ANSWER: \n",
    "\n",
    "{generation}\n",
    "Return JSON with two keys, binary_score is 'yes' or 'no' dependent on whether the criteria is followed. And a key explaination, containing the step-by-step explaination for the answer.\n",
    "\"\"\"\n",
    "\n",
    "# Test\n",
    "answer_grader_prompt_formatted = answer_grader_prompt.format(\n",
    "    question=question, generation=generation\n",
    ")\n",
    "\n",
    "\n",
    "result = llm_json_mode.with_structured_output(ReasoningGrader).invoke(\n",
    "    [SystemMessage(content=answer_grader_instructions)]\n",
    "    + [HumanMessage(content=answer_grader_prompt_formatted)]\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using langgraph to construct the flow of adaptive RAG\n",
    "\n",
    "class AdaptiveRAGState(TypedDict):\n",
    "    question: str \n",
    "    generation: str\n",
    "    web_search: str\n",
    "    max_retries: int\n",
    "    answers: int\n",
    "    loop_step: Annotated[int, operator.add]\n",
    "    documents: List[str]   # list of retrieved documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Nodes\n",
    "# Nodes are nothing but sync or async functions that take in the state and modify it or generate things based on it.\n",
    "\n",
    "def retriever(state: AdaptiveRAGState):\n",
    "    print(\"** RETRIEVE **\")\n",
    "    question = state['question']\n",
    "\n",
    "    # Write retrieved documents to documents in key state\n",
    "    documents = rag_retriever.invoke(question)\n",
    "    return {'documents': documents}\n",
    "\n",
    "\n",
    "def generate(state):\n",
    "    print(\"** GENERATE **\")\n",
    "    question = state['question']\n",
    "    loop_step = state.get('loop_step', 0)  # start with zero loop\n",
    "    documents = state['documents']\n",
    "\n",
    "    # RAG generation\n",
    "    docs_txt = format_docs(documents)\n",
    "    rag_prompt_formatted = rag_prompt.format(context=docs_txt, question=question)\n",
    "    generation = llm.invoke([HumanMessage(content=rag_prompt_formatted)])\n",
    "    \n",
    "    return {'generation': generation, 'loop_step': loop_step + 1}\n",
    "\n",
    "\n",
    "def grade_documents(state):\n",
    "    print(\"** CHECK DOCUMENT RELEVANCE **\")\n",
    "\n",
    "    question = state['question']\n",
    "    documents = state['documents']\n",
    "\n",
    "    # score each doc\n",
    "    filtered_docs = []\n",
    "    websearch = \"no\"\n",
    "    for doc in documents:\n",
    "        doc_grader_prompt_formatted = doc_grader_prompt.format(document=doc.page_content, question=question)\n",
    "        result = llm_json_mode.with_structured_output(Grader).invoke([SystemMessage(content=doc_grader_instructions)] + [HumanMessage(content=doc_grader_prompt_formatted)])\n",
    "\n",
    "        grade = result.binary_score\n",
    "        # Document relevant\n",
    "        if grade.lower() == \"yes\":\n",
    "            print(\"** GRADE: DOCUMENT RELEVANT **\")\n",
    "            filtered_docs.append(doc)\n",
    "        \n",
    "        else:\n",
    "            print(\"** GRADE: DOCUMENT IRRELEVANT\")\n",
    "            websearch = 'yes'\n",
    "            continue\n",
    "        \n",
    "        return {'documents': filtered_docs, 'web_search': websearch}\n",
    "\n",
    "\n",
    "def web_search(state):\n",
    "\n",
    "    question = state['question']\n",
    "    documents = state.get('documents', [])\n",
    "\n",
    "    print(\"** WEB SEARCH **\")\n",
    "\n",
    "    docs = web_search_tool.invoke({'query': question})\n",
    "    web_results = \"\\n\".join([doc['content'] for doc in docs])\n",
    "    web_results = Document(page_content=web_results)\n",
    "\n",
    "    documents.append(web_results)\n",
    "\n",
    "    return {\n",
    "        'documents': documents\n",
    "    }\n",
    "\n",
    "\n",
    "## Edges\n",
    "\n",
    "def route_question(state):\n",
    "    print(\"** ROUTE QUESTION **\")\n",
    "    route_question = llm_json_mode.invoke([SystemMessage(content=router_instructions)] + [HumanMessage(content=state['question'])])\n",
    "\n",
    "    source = json.loads(route_question.content)['datasource']\n",
    "\n",
    "    print(source)\n",
    "\n",
    "    if source == 'websearch':\n",
    "        print(\"** ROUTING TO: websearch **\")\n",
    "        return 'websearch'\n",
    "    elif source == \"vectorstore\":\n",
    "        print(\"** ROUTING TO: retriever **\")\n",
    "        return 'vectorstore'\n",
    "\n",
    "\n",
    "def decide_to_generate(state):\n",
    "    print(\"** ASSESS GRADED DOCUMENTS **\")\n",
    "\n",
    "    question = state['question']\n",
    "    filtered_documents = state['documents']\n",
    "    websearch = state['web_search']\n",
    "\n",
    "    if websearch == \"yes\":\n",
    "        # All documents have been filtered \n",
    "        print(\"** DECISION: NOT ALL DOCUMENTS ARE RELEVANT\")\n",
    "        return 'websearch'\n",
    "    \n",
    "    else:\n",
    "        # All the documents are relevant\n",
    "        print(\"** DECISION: GENERATE **\")\n",
    "        return 'generate'\n",
    "\n",
    "\n",
    "def grade_generation_w_documents_and_question(state):\n",
    "\n",
    "    print(\"** CHECK FOR HALLUCINATIONS **\")\n",
    "    question = state['question']\n",
    "    documents = state['documents']\n",
    "    generation = state['generation']\n",
    "    max_retries = state.get('max_retries', 3)  # keep default retries to 3 if not specified\n",
    "\n",
    "    hallucination_grader_prompt_formatted = hallucination_grader_prompt.format(facts=format_docs(documents), generation=generation)\n",
    "    result = llm_json_mode.with_structured_output(ReasoningGrader).invoke([SystemMessage(content=hallucination_instructions)] + [HumanMessage(content=hallucination_grader_prompt_formatted)])\n",
    "    grade = result.binary_score\n",
    "\n",
    "    if grade == 'yes':\n",
    "        print(\"** DECISION: THE ANSWER IS GROUNDED IN DOCUMENTS**\")\n",
    "        # Check the answer relevance in question\n",
    "        answer_grader_prompt_formatted = answer_grader_prompt.format(question=question, generation=generation)\n",
    "\n",
    "        answer_grade = llm_json_mode.with_structured_output(ReasoningGrader).invoke([SystemMessage(content=answer_grader_instructions), HumanMessage(content=answer_grader_prompt_formatted)])\n",
    "\n",
    "        if answer_grade.binary_score == 'yes':\n",
    "            # The answer is relevant in the question\n",
    "            return 'useful'\n",
    "        elif state['loop_step'] <= max_retries:\n",
    "            # The answer is not useful but we can retry\n",
    "            return 'not useful'\n",
    "        else:\n",
    "            # the answer is not useful and we can't retry\n",
    "            return 'max_retries'\n",
    "    \n",
    "    elif state['loop_step'] <= max_retries:\n",
    "        # the answer is not relevant to the context but we can retry\n",
    "        return 'not supported'\n",
    "    \n",
    "    else:\n",
    "        return 'max_retries'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Construct the graph\n",
    "\n",
    "graph = StateGraph(AdaptiveRAGState)\n",
    "\n",
    "# define the nodes\n",
    "graph.add_node(\"websearch\", web_search)\n",
    "graph.add_node(\"retriever\", retriever)\n",
    "graph.add_node(\"grade_documents\", grade_documents)\n",
    "graph.add_node(\"generate\", generate)\n",
    "\n",
    "# define the edges and conditional edges\n",
    "\n",
    "graph.set_conditional_entry_point(route_question, {'websearch': 'websearch', 'vectorstore': 'retriever'})\n",
    "graph.add_edge('websearch', 'generate')\n",
    "graph.add_edge('retriever', 'grade_documents')\n",
    "graph.add_conditional_edges(\"grade_documents\", decide_to_generate, {'websearch': \"websearch\", \"generate\": \"generate\"})\n",
    "graph.add_conditional_edges(\"generate\", grade_generation_w_documents_and_question, {\"not supported\": \"generate\", \"useful\": END, \"not useful\": \"websearch\", \"max_retries\": END})\n",
    "\n",
    "\n",
    "# compile\n",
    "adaptive_rag = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(adaptive_rag.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** ROUTE QUESTION **\n",
      "websearch\n",
      "** ROUTING TO: websearch **\n",
      "{'question': 'What are the features of the newly released Llama3.2 models?', 'max_retries': 3, 'loop_step': 0}\n",
      "** WEB SEARCH **\n",
      "{'question': 'What are the features of the newly released Llama3.2 models?', 'max_retries': 3, 'loop_step': 0, 'documents': [Document(metadata={}, page_content='Llama 3.2 is Meta’s first open-source AI model capable of processing both text and images. Llama 3.2 1B and 3B Model Performance. Llama 3.2 introduces multimodal models (11B and 90B) that can process both text and images. Llama 3.2 incorporates a new adapter architecture for vision models, integrating image encoder representations. As the first Llama models capable of handling vision tasks, the 11B and 90B models required a new architecture designed to support image reasoning. The team applied two techniques — pruning and distillation — to the 1B and 3B models, making them the first highly capable, lightweight Llama models that can efficiently run on devices.\\nLlama 3.2 includes multilingual text-only models (1B, 3B) and text-image models (11B, 90B), with quantized versions of 1B and 3B offering on average up to 56% smaller size and 2-3x speedup, ideal for on-device and edge deployments. Running powerful, smaller footprint Llamas on Arm CPUs delivers major performance and efficiency benefits and a simple, seamless developer experience which will ultimately accelerate AI deployment across the breadth of mobile and edge markets, built on Arm. We’re excited to continue collaborating with Meta to bring Llama 3.2 to devices powered by Snapdragon and Qualcomm platforms—empowering developers to create innovative generative AI applications that can run on edge devices. “We’re excited to continue collaborating with Meta to bring Llama 3.2 to devices powered by Snapdragon and Qualcomm platforms—empowering developers to create innovative generative AI applications that can run on edge devices.”\\nLlama 3.2 11B & 90B Vision Models Use cases of Llama vision models How Llama 3.2 vision models work To enable the Llama 3.2 vision models to understand both text and images, Meta integrated a pre-trained image encoder into the existing language model using special adapters. Llama 3.2 1B & 3B Lightweight Models Meta’s release of Llama 3.2 introduces the first multimodal models in the series, focusing on two key areas: vision-enabled models and lightweight models for edge and mobile devices. It also offers lightweight models designed for efficient use on edge and mobile devices, unlike Llama 3.1, which was focused primarily on text processing. Llama 3.2 vision models perform competitively, excelling in tasks involving image and text reasoning.\\nMeta Releases Llama 3.2—and Gives Its AI a Voice | WIRED Meta Releases Llama 3.2—and Gives Its AI a Voice Meta Releases Llama 3.2—and Gives Its AI a Voice Meta today also announced Llama 3.2, the first version of its free AI models to have visual abilities, broadening their usefulness and relevance for robotics, virtual reality, and so-called AI agents. Powering Meta AI’s new capabilities is an upgraded version of Llama, Meta’s premier large language model. “With Llama 3.1, Meta showed that open models could finally close the gap with their proprietary counterparts,” says Nathan Benaich, founder and general partner of Air Street Capital, and the author of an influential yearly report on AI.\\nTen open-weight models (5 multimodal models and 5 text-only ones) are available on the Hub. Llama 3.2 Vision comes in two sizes: 11B for efficient deployment and development on consumer-size GPU, and 90B for large-scale applications. Llama 3.2 also includes small text-only language models that can run on-device. There’s also a small 1B version of Llama Guard that can be deployed alongside these or the larger text models in production use cases. The Llama 3.2 collection includes 1B and 3B text models. There is also a new small version of Llama Guard, Llama Guard 3 1B, that can be deployed with these models to evaluate the last user or assistant responses in a multi-turn conversation. model_id = \"meta-llama/Llama-3.2-3B-Instruct\" model_id = \"meta-llama/Llama-3.2-11B-Vision-Instruct\" --model_name_or_path meta-llama/Llama-3.2-11B-Vision-Instruct \\\\')]}\n",
      "** GENERATE **\n",
      "** CHECK FOR HALLUCINATIONS **\n",
      "** DECISION: THE ANSWER IS GROUNDED IN DOCUMENTS**\n",
      "{'question': 'What are the features of the newly released Llama3.2 models?', 'generation': AIMessage(content='The Llama 3.2 models feature multimodal capabilities, enabling them to process both text and images. The models also include a new adapter architecture for vision models, integrating image encoder representations, making them capable of handling vision tasks. Additionally, the models are designed to be lightweight and efficient, with quantized versions available that offer up to 56% smaller size and 2-3x speedup for on-device deployments.', additional_kwargs={}, response_metadata={'model': 'llama3.2:3b-instruct-fp16', 'created_at': '2024-11-11T11:53:14.202630278Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 1196201624, 'load_duration': 15739611, 'prompt_eval_count': 1026, 'prompt_eval_duration': 92564000, 'eval_count': 87, 'eval_duration': 1045996000}, id='run-b0fc81f1-47a2-4446-98b9-df9cdbedbcb2-0', usage_metadata={'input_tokens': 1026, 'output_tokens': 87, 'total_tokens': 1113}), 'max_retries': 3, 'loop_step': 1, 'documents': [Document(metadata={}, page_content='Llama 3.2 is Meta’s first open-source AI model capable of processing both text and images. Llama 3.2 1B and 3B Model Performance. Llama 3.2 introduces multimodal models (11B and 90B) that can process both text and images. Llama 3.2 incorporates a new adapter architecture for vision models, integrating image encoder representations. As the first Llama models capable of handling vision tasks, the 11B and 90B models required a new architecture designed to support image reasoning. The team applied two techniques — pruning and distillation — to the 1B and 3B models, making them the first highly capable, lightweight Llama models that can efficiently run on devices.\\nLlama 3.2 includes multilingual text-only models (1B, 3B) and text-image models (11B, 90B), with quantized versions of 1B and 3B offering on average up to 56% smaller size and 2-3x speedup, ideal for on-device and edge deployments. Running powerful, smaller footprint Llamas on Arm CPUs delivers major performance and efficiency benefits and a simple, seamless developer experience which will ultimately accelerate AI deployment across the breadth of mobile and edge markets, built on Arm. We’re excited to continue collaborating with Meta to bring Llama 3.2 to devices powered by Snapdragon and Qualcomm platforms—empowering developers to create innovative generative AI applications that can run on edge devices. “We’re excited to continue collaborating with Meta to bring Llama 3.2 to devices powered by Snapdragon and Qualcomm platforms—empowering developers to create innovative generative AI applications that can run on edge devices.”\\nLlama 3.2 11B & 90B Vision Models Use cases of Llama vision models How Llama 3.2 vision models work To enable the Llama 3.2 vision models to understand both text and images, Meta integrated a pre-trained image encoder into the existing language model using special adapters. Llama 3.2 1B & 3B Lightweight Models Meta’s release of Llama 3.2 introduces the first multimodal models in the series, focusing on two key areas: vision-enabled models and lightweight models for edge and mobile devices. It also offers lightweight models designed for efficient use on edge and mobile devices, unlike Llama 3.1, which was focused primarily on text processing. Llama 3.2 vision models perform competitively, excelling in tasks involving image and text reasoning.\\nMeta Releases Llama 3.2—and Gives Its AI a Voice | WIRED Meta Releases Llama 3.2—and Gives Its AI a Voice Meta Releases Llama 3.2—and Gives Its AI a Voice Meta today also announced Llama 3.2, the first version of its free AI models to have visual abilities, broadening their usefulness and relevance for robotics, virtual reality, and so-called AI agents. Powering Meta AI’s new capabilities is an upgraded version of Llama, Meta’s premier large language model. “With Llama 3.1, Meta showed that open models could finally close the gap with their proprietary counterparts,” says Nathan Benaich, founder and general partner of Air Street Capital, and the author of an influential yearly report on AI.\\nTen open-weight models (5 multimodal models and 5 text-only ones) are available on the Hub. Llama 3.2 Vision comes in two sizes: 11B for efficient deployment and development on consumer-size GPU, and 90B for large-scale applications. Llama 3.2 also includes small text-only language models that can run on-device. There’s also a small 1B version of Llama Guard that can be deployed alongside these or the larger text models in production use cases. The Llama 3.2 collection includes 1B and 3B text models. There is also a new small version of Llama Guard, Llama Guard 3 1B, that can be deployed with these models to evaluate the last user or assistant responses in a multi-turn conversation. model_id = \"meta-llama/Llama-3.2-3B-Instruct\" model_id = \"meta-llama/Llama-3.2-11B-Vision-Instruct\" --model_name_or_path meta-llama/Llama-3.2-11B-Vision-Instruct \\\\')]}\n"
     ]
    }
   ],
   "source": [
    "## TEST\n",
    "inputs = {\"question\": \"What are the features of the newly released Llama3.2 models?\", \"max_retries\": 3}\n",
    "for event in adaptive_rag.stream(inputs, stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
